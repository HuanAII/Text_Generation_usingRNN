{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9mGVHZKvratP86ZTXrTV0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuanAII/Text_Generation_usingRNN/blob/main/Transformer_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H-kjt_2xDsdD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer=nn.TransformerEncoderLayer(\n",
        "    d_model=3,\n",
        "    nhead=1,\n",
        "    batch_first=True,\n",
        "    dim_feedforward=4,\n",
        "    dropout=0.1,\n",
        "    bias=False\n",
        ")\n",
        "\n",
        "#Run check\n",
        "example=torch.randn(1,2,3)\n",
        "example\n",
        "output=encoder_layer(example)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L06B5rnMFmjn",
        "outputId": "1b4b67ec-b0b4-431b-8cf5-aa662fab9fdc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.2955, -0.1566, -1.1389],\n",
              "         [ 0.3669,  0.9993, -1.3663]]], grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tu cai dat\n",
        "\n",
        "# x = encoder_layer.self_attn(src, src, src)[0]\n",
        "# x = src + x\n",
        "# x1 = encoder_layer.norm1(x)\n",
        "# x = encoder_layer.linear2( torch.nn.ReLU()(encoder_layer.linear1(x1)) )\n",
        "# x = x + x1\n",
        "# x = encoder_layer.norm2(x)\n",
        "# print(x)"
      ],
      "metadata": {
        "id": "Hh3_U1NNHQT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Masked Encoder*\n",
        "\n"
      ],
      "metadata": {
        "id": "imApJsnqHiRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "encoder_layer=nn.TransformerEncoderLayer(d_model=3,\n",
        "                                         nhead=1,\n",
        "                                         batch_first=True,\n",
        "                                         dim_feedforward=4,\n",
        "                                         dropout=0.1,\n",
        "                                         bias=False\n",
        "                                         )\n",
        "mask=torch.triu(torch.ones(3,3), diagonal=1).bool()#giu lai tam giac tren chuyen sang diagonal=1 thanh True\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbvOHvxlHpXY",
        "outputId": "dd6d8aec-d20a-46be-bb7a-bf9a63f0e2ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True],\n",
              "        [False, False,  True],\n",
              "        [False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src = torch.Tensor([[[ 0.69,  0.72, -1.41],\n",
        "                     [ 0.21,  1.10, -1.31],\n",
        "                     [-0.88,  0.60, -0.31]]])\n",
        "out = encoder_layer(src, src_mask=mask)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75oOwTSzIUJ0",
        "outputId": "2fe2b8fe-081a-4916-b8b2-7dbc7ab92353"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.3610, -0.3478, -1.0132],\n",
            "         [ 1.0445,  0.3035, -1.3479],\n",
            "         [-0.8709,  1.4004, -0.5295]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9M98ed3TImgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Transformer***"
      ],
      "metadata": {
        "id": "Es-mukoEInSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "qv31GgXSIrTI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer=nn.TransformerEncoderLayer(d_model=3,\n",
        "                                         nhead=1,\n",
        "                                         batch_first=True,\n",
        "                                         dim_feedforward=4,\n",
        "                                         dropout=0.1,\n",
        "                                         bias=False\n",
        "                                         )\n",
        "\n",
        "src = torch.Tensor([[[0.48, 0.44, 0.71],\n",
        "                     [0.65, 0.80, 0.79]]])\n",
        "context = encoder_layer(src)\n",
        "print(context)\n",
        "#shape input == output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkX1xUurIvqM",
        "outputId": "1c444ae4-58b8-4e43-fefe-fce80a2109e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.1828, -1.2628,  0.0800],\n",
            "         [ 1.2194,  0.0106, -1.2300]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_layer = nn.TransformerDecoderLayer(d_model=3,\n",
        "                                           nhead=1,\n",
        "                                           batch_first=True,\n",
        "                                           dim_feedforward=4,\n",
        "                                           dropout=0.0,\n",
        "                                           bias=False)\n",
        "\n",
        "target = torch.Tensor( [[[0.3516, 0.9509, 0.2771],\n",
        "                         [0.1993, 0.0177, 0.2628],\n",
        "                         [0.0774, 0.5253, 0.6413],\n",
        "                         [0.6749, 0.5501, 0.1641]]])\n",
        "print(target.shape)\n",
        "\n",
        "out=decoder_layer(target, context)#tham chiếu đến encoder để sinh ra từ tiếp theo\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHOY42XJJIcm",
        "outputId": "64a706d1-5691-4415-886c-3289c1e25947"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 3])\n",
            "tensor([[[-0.5717,  1.4060, -0.8344],\n",
            "         [ 0.6040, -1.4094,  0.8054],\n",
            "         [-0.8176, -0.5905,  1.4081],\n",
            "         [ 1.4043, -0.8467, -0.5576]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MaskTransformer"
      ],
      "metadata": {
        "id": "ltO6pdF_KedH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_layer = nn.TransformerEncoderLayer(d_model=3,\n",
        "                                           nhead=1,\n",
        "                                           batch_first=True,\n",
        "                                           dim_feedforward=4,\n",
        "                                           dropout=0.0,\n",
        "                                           bias=False)\n",
        "\n",
        "decoder_layer = nn.TransformerDecoderLayer(d_model=3,\n",
        "                                           nhead=1,\n",
        "                                           batch_first=True,\n",
        "                                           dim_feedforward=4,\n",
        "                                           dropout=0.0,\n",
        "                                           bias=False)\n",
        "\n",
        "tgt = torch.Tensor([[[0.3516, 0.9509, 0.2771],\n",
        "                     [0.1993, 0.0177, 0.2628],\n",
        "                     [0.0774, 0.5253, 0.6413],\n",
        "                     [0.6749, 0.5501, 0.1641]]])\n",
        "\n",
        "context = encoder_layer(src)\n",
        "mask = torch.triu(torch.ones(4, 4), diagonal=1).bool()\n",
        "out = decoder_layer(tgt, context, tgt_mask=mask)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qZTg_D3Kit4",
        "outputId": "3dbb1b22-2b60-4d7d-e2f7-f268ceef1ce1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.0517,  1.3447, -0.2930],\n",
            "         [-1.0491, -0.2968,  1.3459],\n",
            "         [-1.4123,  0.6429,  0.7694],\n",
            "         [ 0.5907,  0.8174, -1.4081]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    }
  ]
}